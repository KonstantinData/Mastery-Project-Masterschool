{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff2611cc",
   "metadata": {},
   "source": [
    "# **EDA & Feature Engneering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45899623",
   "metadata": {},
   "source": [
    "## üì• Load Data from AWS S3 Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f830df5c",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è No accesdetails needed for this Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "99c080d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_flights_bronze():\n",
    "    url = \"https://lakehouse-masteryproject-2025.s3.eu-north-1.amazonaws.com/bronze/public_flights_export_2025-03-31_134734.csv\"\n",
    "    return pd.read_csv(url)\n",
    "\n",
    "def load_hotels_bronze():\n",
    "    url = \"https://lakehouse-masteryproject-2025.s3.eu-north-1.amazonaws.com/bronze/public_hotels_export_2025-03-31_171805.csv\"\n",
    "    return pd.read_csv(url)\n",
    "\n",
    "def load_sessions_bronze():\n",
    "    url = \"https://lakehouse-masteryproject-2025.s3.eu-north-1.amazonaws.com/bronze/public_sessions_export_2025-03-31_221253.csv\"\n",
    "    return pd.read_csv(url)\n",
    "\n",
    "def load_users_bronze():\n",
    "    url = \"https://lakehouse-masteryproject-2025.s3.eu-north-1.amazonaws.com/bronze/public_users_export_2025-04-01_101058.csv\"\n",
    "    return pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9ab82064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Flight, hotel, session and user data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "df_flights_bronze = load_flights_bronze()\n",
    "df_hotels_bronze = load_hotels_bronze()\n",
    "df_sessions_bronze = load_sessions_bronze()\n",
    "df_users_bronze = load_users_bronze()\n",
    "\n",
    "print(\"‚úÖ Flight, hotel, session and user data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3084a73b",
   "metadata": {},
   "source": [
    "## üîçReducing Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5abaf1",
   "metadata": {},
   "source": [
    "The next step is to reduce the columns to only those needed to validate the hypotheses behind the defined perks. All other columns are excluded unless they are required to calculate new features (e.g., `nights` for trip duration) or to support the interpretation of results.\n",
    "\n",
    "üß† Personalization Scope (Project Context)\n",
    "\n",
    "In this project, **personalization** is based exclusively on **individual user behavior** observed within the TravelTide platform. This includes patterns such as discount usage, booking behavior, and cancellation frequency.\n",
    "\n",
    "Demographic or group-level attributes (e.g. family status, number of travelers, or room count) are not considered. The goal is to assign each user the perk most relevant to **how they interact** with the platform ‚Äî not who they are or who they travel with.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699efc82",
   "metadata": {},
   "source": [
    "### üë§ Reducing Columns ‚Äì `users` Table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f304530a",
   "metadata": {},
   "source": [
    "\n",
    "For the `users` table, we keep only the columns required to support the behavioral logic behind the defined perks. Since personalization in this project is based purely on **individual interaction behavior**, we exclude all demographic and group-related attributes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23bfb5e",
   "metadata": {},
   "source": [
    "| Column         | Description                                                           | Keep? |\n",
    "|----------------|------------------------------------------------------------------------|:-----:|\n",
    "| `user_id`      | Required to join with sessions and flights                            | ‚úÖ    |\n",
    "| `birthdate`    | May support age-related behavioral segmentation if needed             | ‚úÖ    |\n",
    "| `has_children` | Not used for any defined perk ‚Äî group/family-related                  | ‚ùå    |\n",
    "| `gender`       | Not tied to any perk                                                  | ‚ùå    |\n",
    "| `married`      | Not tied to any perk                                                  | ‚ùå    |\n",
    "| `home_country` | Not required for perk logic                                           | ‚ùå    |\n",
    "| `home_city`    | Too granular for this scope                                           | ‚ùå    |\n",
    "| `home_airport` | Not relevant for current perks                                        | ‚ùå    |\n",
    "| `sign_up_date` | Not used in perk logic                                                | ‚ùå    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dd060fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "birthdate",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "298fc398-7b20-4091-b393-40e2073a2814",
       "rows": [
        [
         "0",
         "0",
         "1990-01-22"
        ],
        [
         "1",
         "1",
         "2000-11-08"
        ],
        [
         "2",
         "2",
         "1992-09-21"
        ],
        [
         "3",
         "3",
         "1996-11-27"
        ],
        [
         "4",
         "4",
         "1978-01-05"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>birthdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1990-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2000-11-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1992-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1996-11-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1978-01-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id   birthdate\n",
       "0        0  1990-01-22\n",
       "1        1  2000-11-08\n",
       "2        2  1992-09-21\n",
       "3        3  1996-11-27\n",
       "4        4  1978-01-05"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_users_bronze = df_users_bronze[[\"user_id\", \"birthdate\"]]\n",
    "\n",
    "df_users_bronze.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c163e215",
   "metadata": {},
   "source": [
    "### üßæ Reducing Columns ‚Äì `sessions` Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040efc87",
   "metadata": {},
   "source": [
    "\n",
    "The `sessions` table is the most important source for behavioral signals in this project. We retain only the columns directly required to support the five defined perks or essential to filtering and joining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196e8923",
   "metadata": {},
   "source": [
    "| Column                   | Description                                                                 | Keep? |\n",
    "|--------------------------|-----------------------------------------------------------------------------|:-----:|\n",
    "| `session_id`             | Needed to count sessions per user (7+ sessions filter)                      | ‚úÖ    |\n",
    "| `user_id`                | Required to join with users                                                 | ‚úÖ    |\n",
    "| `trip_id`                | Required to connect to flights and hotels                                   | ‚úÖ    |\n",
    "| `session_start`          | Used to filter sessions after Jan 4, 2023                                   | ‚úÖ    |\n",
    "| `flight_discount`        | Supports the \"exclusive discounts\" perk                                     | ‚úÖ    |\n",
    "| `hotel_discount`         | Supports the \"exclusive discounts\" perk                                     | ‚úÖ    |\n",
    "| `flight_discount_amount` | Captures price sensitivity for flight discounts                             | ‚úÖ    |\n",
    "| `hotel_discount_amount`  | Captures price sensitivity for hotel discounts                              | ‚úÖ    |\n",
    "| `flight_booked`          | Required to understand booking behavior                                     | ‚úÖ    |\n",
    "| `hotel_booked`           | Required to validate hotel+flight pairing                                   | ‚úÖ    |\n",
    "| `page_clicks`            | Indicates user engagement ‚Äî helps understand interaction effort             | ‚úÖ    |\n",
    "| `cancellation`           | Directly supports the \"no cancellation fees\" perk                           | ‚úÖ    |\n",
    "| `session_end`            | Not required for any of the defined perks                                   | ‚ùå    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "13f460d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "session_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "user_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "trip_id",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "session_start",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "flight_discount",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "hotel_discount",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "flight_discount_amount",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hotel_discount_amount",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flight_booked",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "hotel_booked",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "page_clicks",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cancellation",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "76d7b646-327d-49c8-bf03-53970834ad67",
       "rows": [
        [
         "0",
         "841803-95c93659053948049c73106ffdcf4df6",
         "841803",
         "841803-31d33d39b08f477bb8d9dd3b0dcbf1d3",
         "2023-05-17 19:40:00",
         "False",
         "False",
         null,
         null,
         "True",
         "True",
         "30",
         "False"
        ],
        [
         "1",
         "841804-bf1bfe452c4d4372b04d9612134006e7",
         "841804",
         null,
         "2023-05-17 22:40:00",
         "False",
         "False",
         null,
         null,
         "False",
         "False",
         "9",
         "False"
        ],
        [
         "2",
         "841805-70d695ee6540481bae7750e368c10443",
         "841805",
         "841805-506d17340ffa41659736fd258138a9b5",
         "2023-05-17 21:10:00",
         "False",
         "False",
         null,
         null,
         "True",
         "True",
         "24",
         "False"
        ],
        [
         "3",
         "841806-a03ac981d1c847979765669ca871a0cb",
         "841806",
         null,
         "2023-05-17 21:49:00",
         "True",
         "True",
         "0.2",
         "0.2",
         "False",
         "False",
         "42",
         "False"
        ],
        [
         "4",
         "841807-4febb023cd414a6196fc026af1928bfb",
         "841807",
         null,
         "2023-05-17 20:28:00",
         "False",
         "False",
         null,
         null,
         "False",
         "False",
         "4",
         "False"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>session_start</th>\n",
       "      <th>flight_discount</th>\n",
       "      <th>hotel_discount</th>\n",
       "      <th>flight_discount_amount</th>\n",
       "      <th>hotel_discount_amount</th>\n",
       "      <th>flight_booked</th>\n",
       "      <th>hotel_booked</th>\n",
       "      <th>page_clicks</th>\n",
       "      <th>cancellation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>841803-95c93659053948049c73106ffdcf4df6</td>\n",
       "      <td>841803</td>\n",
       "      <td>841803-31d33d39b08f477bb8d9dd3b0dcbf1d3</td>\n",
       "      <td>2023-05-17 19:40:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>841804-bf1bfe452c4d4372b04d9612134006e7</td>\n",
       "      <td>841804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-17 22:40:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>841805-70d695ee6540481bae7750e368c10443</td>\n",
       "      <td>841805</td>\n",
       "      <td>841805-506d17340ffa41659736fd258138a9b5</td>\n",
       "      <td>2023-05-17 21:10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>841806-a03ac981d1c847979765669ca871a0cb</td>\n",
       "      <td>841806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-17 21:49:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>42</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>841807-4febb023cd414a6196fc026af1928bfb</td>\n",
       "      <td>841807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-17 20:28:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                session_id  user_id  \\\n",
       "0  841803-95c93659053948049c73106ffdcf4df6   841803   \n",
       "1  841804-bf1bfe452c4d4372b04d9612134006e7   841804   \n",
       "2  841805-70d695ee6540481bae7750e368c10443   841805   \n",
       "3  841806-a03ac981d1c847979765669ca871a0cb   841806   \n",
       "4  841807-4febb023cd414a6196fc026af1928bfb   841807   \n",
       "\n",
       "                                   trip_id        session_start  \\\n",
       "0  841803-31d33d39b08f477bb8d9dd3b0dcbf1d3  2023-05-17 19:40:00   \n",
       "1                                      NaN  2023-05-17 22:40:00   \n",
       "2  841805-506d17340ffa41659736fd258138a9b5  2023-05-17 21:10:00   \n",
       "3                                      NaN  2023-05-17 21:49:00   \n",
       "4                                      NaN  2023-05-17 20:28:00   \n",
       "\n",
       "   flight_discount  hotel_discount  flight_discount_amount  \\\n",
       "0            False           False                     NaN   \n",
       "1            False           False                     NaN   \n",
       "2            False           False                     NaN   \n",
       "3             True            True                     0.2   \n",
       "4            False           False                     NaN   \n",
       "\n",
       "   hotel_discount_amount  flight_booked  hotel_booked  page_clicks  \\\n",
       "0                    NaN           True          True           30   \n",
       "1                    NaN          False         False            9   \n",
       "2                    NaN           True          True           24   \n",
       "3                    0.2          False         False           42   \n",
       "4                    NaN          False         False            4   \n",
       "\n",
       "   cancellation  \n",
       "0         False  \n",
       "1         False  \n",
       "2         False  \n",
       "3         False  \n",
       "4         False  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sessions_bronze = df_sessions_bronze[\n",
    "    [\n",
    "        \"session_id\", \"user_id\", \"trip_id\", \"session_start\",\n",
    "        \"flight_discount\", \"hotel_discount\",\n",
    "        \"flight_discount_amount\", \"hotel_discount_amount\",\n",
    "        \"flight_booked\", \"hotel_booked\",\n",
    "        \"page_clicks\", \"cancellation\"\n",
    "    ]\n",
    "]\n",
    "df_sessions_bronze.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad837ed0",
   "metadata": {},
   "source": [
    "### ‚úàÔ∏è Reducing Columns ‚Äì `flights` Table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f7a8e8",
   "metadata": {},
   "source": [
    "\n",
    "We retain only the columns that are directly required to support perk validation. Columns related to destinations, time, or route details are excluded, as none of the five defined perks depend on them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afc5d83",
   "metadata": {},
   "source": [
    "| Column                   | Description                                                                                  |\n",
    "|--------------------------|----------------------------------------------------------------------------------------------|\n",
    "| `trip_id`                | ‚úÖ Required to join with sessions                                                             |\n",
    "| `checked_bags`           | ‚úÖ Directly supports the \"free checked bag\" perk                                              |\n",
    "| `base_fare_usd`          | ‚úÖ Supports the \"exclusive discounts\" perk by capturing price sensitivity                     |\n",
    "| `trip_airline`           | ‚ùå Not needed for current perks                                                               |\n",
    "| `origin_airport`         | ‚ùå Not required for any defined perk                                                          |\n",
    "| `destination`            | ‚ùå Not required for any defined perk                                                          |\n",
    "| `destination_airport`    | ‚ùå Redundant and not perk-related                                                             |\n",
    "| `seats`                  | ‚ùå Not needed for defined perks                                                               |\n",
    "| `return_flight_booked`   | ‚ùå Not used for any current perk                                                              |\n",
    "| `departure_time`         | ‚ùå Not used for any current perk                                                              |\n",
    "| `return_time`            | ‚ùå Not used for any current perk                                                              |\n",
    "| `destination_airport_lat`| ‚ùå Mapping only ‚Äî not used in perks                                                           |\n",
    "| `destination_airport_lon`| ‚ùå Mapping only ‚Äî not used in perks                                                           |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1128ebaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "trip_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "checked_bags",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "base_fare_usd",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "6c66acca-fa83-488b-a2a9-0346f251fa3a",
       "rows": [
        [
         "0",
         "693092-7b8767746abd45219ed468d58da9f702",
         "0",
         "479.31"
        ],
        [
         "1",
         "693124-1032149a9e01427da914b17ce6ef1926",
         "0",
         "575.78"
        ],
        [
         "2",
         "693149-0fdb31c7dc114a4d8a318f0feada365c",
         "0",
         "336.72"
        ],
        [
         "3",
         "693169-d120c3721d0b4bcca278639c981e4322",
         "0",
         "295.37"
        ],
        [
         "4",
         "693181-f4a2363db0ee452f8ac8c0fe3d4ef0ad",
         "1",
         "694.26"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>checked_bags</th>\n",
       "      <th>base_fare_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>693092-7b8767746abd45219ed468d58da9f702</td>\n",
       "      <td>0</td>\n",
       "      <td>479.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>693124-1032149a9e01427da914b17ce6ef1926</td>\n",
       "      <td>0</td>\n",
       "      <td>575.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>693149-0fdb31c7dc114a4d8a318f0feada365c</td>\n",
       "      <td>0</td>\n",
       "      <td>336.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693169-d120c3721d0b4bcca278639c981e4322</td>\n",
       "      <td>0</td>\n",
       "      <td>295.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>693181-f4a2363db0ee452f8ac8c0fe3d4ef0ad</td>\n",
       "      <td>1</td>\n",
       "      <td>694.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   trip_id  checked_bags  base_fare_usd\n",
       "0  693092-7b8767746abd45219ed468d58da9f702             0         479.31\n",
       "1  693124-1032149a9e01427da914b17ce6ef1926             0         575.78\n",
       "2  693149-0fdb31c7dc114a4d8a318f0feada365c             0         336.72\n",
       "3  693169-d120c3721d0b4bcca278639c981e4322             0         295.37\n",
       "4  693181-f4a2363db0ee452f8ac8c0fe3d4ef0ad             1         694.26"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flights_bronze = df_flights_bronze[\n",
    "    [\"trip_id\", \"checked_bags\", \"base_fare_usd\"]\n",
    "]\n",
    "\n",
    "df_flights_bronze.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a288e412",
   "metadata": {},
   "source": [
    "### üè® Reducing Columns ‚Äì `hotels` Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b865abe",
   "metadata": {},
   "source": [
    "In the `hotels` table, we only keep columns that are directly needed to validate the defined perks. All other fields, such as room count, hotel brand, or check-in/out times, are excluded since they are not required for any of the five perks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0add020e",
   "metadata": {},
   "source": [
    "| Column               | Description                                                                                   |\n",
    "|----------------------|-----------------------------------------------------------------------------------------------|\n",
    "| `trip_id`            | ‚úÖ Required to join hotels with sessions and flights                                          |\n",
    "| `nights`             | ‚úÖ Required to validate the \"1 night free hotel with flight\" perk                             |\n",
    "| `hotel_per_room_usd` | ‚úÖ Supports the \"exclusive discounts\" perk by capturing price sensitivity                      |\n",
    "| `hotel_name`         | ‚ùå Not needed for any defined perk                                                             |\n",
    "| `rooms`              | ‚ùå Not used for any current perk                                                               |\n",
    "| `check_in_time`      | ‚ùå Not required for any of the defined perks                                                   |\n",
    "| `check_out_time`     | ‚ùå Not required ‚Äî duration is already captured by `nights`                                     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7dba010d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hotels_bronze = df_hotels_bronze.drop(columns=[\"nights\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a595d7",
   "metadata": {},
   "source": [
    "Instead of relying on the nights column from the dataset, we calculate it ourselves based on actual hote logic: check-in time, check-out time, and a grace period. A late checkout may result in an additional night being counted. This behavior is more realistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7b0dd999",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[95]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m nights\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Apply to dataset\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m df_hotels_bronze[\u001b[33m\"\u001b[39m\u001b[33mnights\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mdf_hotels_bronze\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalculate_nights_realistic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Git-GitHub\\Repositories\\Mastery-Project-Masterschool\\mastery-project-masterschool\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:10374\u001b[39m, in \u001b[36mDataFrame.apply\u001b[39m\u001b[34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[39m\n\u001b[32m  10360\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[32m  10362\u001b[39m op = frame_apply(\n\u001b[32m  10363\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  10364\u001b[39m     func=func,\n\u001b[32m   (...)\u001b[39m\u001b[32m  10372\u001b[39m     kwargs=kwargs,\n\u001b[32m  10373\u001b[39m )\n\u001b[32m> \u001b[39m\u001b[32m10374\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mapply\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Git-GitHub\\Repositories\\Mastery-Project-Masterschool\\mastery-project-masterschool\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[39m, in \u001b[36mFrameApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_raw(engine=\u001b[38;5;28mself\u001b[39m.engine, engine_kwargs=\u001b[38;5;28mself\u001b[39m.engine_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Git-GitHub\\Repositories\\Mastery-Project-Masterschool\\mastery-project-masterschool\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[39m, in \u001b[36mFrameApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1061\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1062\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine == \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1063\u001b[39m         results, res_index = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1064\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1065\u001b[39m         results, res_index = \u001b[38;5;28mself\u001b[39m.apply_series_numba()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Git-GitHub\\Repositories\\Mastery-Project-Masterschool\\mastery-project-masterschool\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[39m, in \u001b[36mFrameApply.apply_series_generator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1078\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[33m\"\u001b[39m\u001b[33mmode.chained_assignment\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1079\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[32m   1080\u001b[39m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1081\u001b[39m         results[i] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1082\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[32m   1083\u001b[39m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[32m   1084\u001b[39m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[32m   1085\u001b[39m             results[i] = results[i].copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[95]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mcalculate_nights_realistic\u001b[39m\u001b[34m(row)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pd.isna(check_in) \u001b[38;5;129;01mor\u001b[39;00m pd.isna(check_out):\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m check_in_date = \u001b[43mcheck_in\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdate\u001b[49m()\n\u001b[32m     18\u001b[39m check_out_date = check_out.date()\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Base night count = number of calendar days\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'date'"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "# Hotel rules\n",
    "CHECKIN_TIME = datetime.strptime(\"15:00\", \"%H:%M\").time()\n",
    "CHECKOUT_TIME = datetime.strptime(\"11:00\", \"%H:%M\").time()\n",
    "GRACE_PERIOD = timedelta(hours=1)  # 1-hour grace period\n",
    "\n",
    "# Function to calculate nights based on check-in/out times\n",
    "def calculate_nights_realistic(row):\n",
    "    check_in = row[\"check_in_time\"]\n",
    "    check_out = row[\"check_out_time\"]\n",
    "\n",
    "    if pd.isna(check_in) or pd.isna(check_out):\n",
    "        return None\n",
    "\n",
    "    check_in_date = check_in.date()\n",
    "    check_out_date = check_out.date()\n",
    "\n",
    "    # Base night count = number of calendar days\n",
    "    nights = (check_out_date - check_in_date).days\n",
    "\n",
    "    # Add 1 night if checkout was late (after grace period)\n",
    "    checkout_deadline = datetime.combine(check_out_date, CHECKOUT_TIME) + GRACE_PERIOD\n",
    "    if check_out > checkout_deadline:\n",
    "        nights += 1\n",
    "\n",
    "    return nights\n",
    "\n",
    "# Apply to dataset\n",
    "df_hotels_bronze[\"nights\"] = df_hotels_bronze.apply(calculate_nights_realistic, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3c269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hotels_bronze = df_hotels_bronze[[\"trip_id\", \"nights\", \"hotel_per_room_usd\"]]\n",
    "\n",
    "df_hotels_bronze.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878667e9",
   "metadata": {},
   "source": [
    "## üîÑ Parse and Standardize Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85160b71",
   "metadata": {},
   "source": [
    "Before we can assign perks or create user-level aggregations, we need to ensure that all four tables ‚Äî `users`, `sessions`, `flights`, and `hotels` ‚Äî are clean and consistent. This includes standardizing data types, handling missing values, and ensuring that binary and datetime fields are correctly formatted.\n",
    "\n",
    "Each table requires slightly different steps, depending on the structure of the data it contains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715da046",
   "metadata": {},
   "source": [
    "### üë§ Data Preparation ‚Äì `users` Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412d0e13",
   "metadata": {},
   "source": [
    "The `users` table contains only two columns needed for the defined perks: `user_id` and `birthdate`. Our main goal here is to ensure `birthdate` is in datetime format so we can calculate user age if needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7402125a",
   "metadata": {},
   "source": [
    "Step 1 ‚Äì Convert Columns to Correct Data Types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a93711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_bronze[\"birthdate\"] = pd.to_datetime(df_users_bronze[\"birthdate\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3ec197",
   "metadata": {},
   "source": [
    "Step 2 ‚Äì Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18e98cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nulls\n",
    "df_users_bronze.isna().sum()\n",
    "\n",
    "# Drop rows with missing user_id or birthdate\n",
    "df_users_bronze = df_users_bronze.dropna(subset=[\"user_id\", \"birthdate\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6109cc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_bronze.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4679d506",
   "metadata": {},
   "source": [
    "### üßæ Data Preparation ‚Äì `sessions` Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64de2ae3",
   "metadata": {},
   "source": [
    "We start by preparing the `sessions` table. The main focus is on:\n",
    "\n",
    "- Ensuring correct data types (especially for datetime and boolean fields)\n",
    "- Handling missing values\n",
    "- Verifying binary logic for downstream scoring and aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc9834b",
   "metadata": {},
   "source": [
    "Step 1 ‚Äì Convert Columns to Correct Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aeb18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sessions_bronze[\"session_start\"] = pd.to_datetime(df_sessions_bronze[\"session_start\"])\n",
    "df_sessions_bronze[\"flight_discount\"] = df_sessions_bronze[\"flight_discount\"].astype(bool)\n",
    "df_sessions_bronze[\"hotel_discount\"] = df_sessions_bronze[\"hotel_discount\"].astype(bool)\n",
    "df_sessions_bronze[\"flight_booked\"] = df_sessions_bronze[\"flight_booked\"].astype(bool)\n",
    "df_sessions_bronze[\"hotel_booked\"] = df_sessions_bronze[\"hotel_booked\"].astype(bool)\n",
    "df_sessions_bronze[\"cancellation\"] = df_sessions_bronze[\"cancellation\"].astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e595a3",
   "metadata": {},
   "source": [
    "Step 2 ‚Äì Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267ba44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nulls\n",
    "df_sessions_bronze.isna().sum()\n",
    "\n",
    "# Drop sessions without user_id or trip_id, which are critical\n",
    "df_sessions_bronze = df_sessions_bronze.dropna(subset=[\"user_id\", \"trip_id\"])\n",
    "\n",
    "# Fill missing discount amounts with 0\n",
    "df_sessions_bronze[\"flight_discount_amount\"] = df_sessions_bronze[\"flight_discount_amount\"].fillna(0)\n",
    "df_sessions_bronze[\"hotel_discount_amount\"] = df_sessions_bronze[\"hotel_discount_amount\"].fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d122c54",
   "metadata": {},
   "source": [
    "Step 3 ‚Äì Validate Binary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1591ec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm binary fields contain only True/False\n",
    "binary_fields = [\"flight_discount\", \"hotel_discount\", \"flight_booked\", \"hotel_booked\", \"cancellation\"]\n",
    "for col in binary_fields:\n",
    "    print(col, df_sessions_bronze[col].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f4ad0e",
   "metadata": {},
   "source": [
    "### ‚úàÔ∏è Data Preparation ‚Äì `flights` Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8c65ee",
   "metadata": {},
   "source": [
    "In the `flights` table, we prepare the data by ensuring correct data types and handling missing values in price and baggage-related columns. Since only three columns are needed to validate the defined perks, we focus cleanup on those specifically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd23ab83",
   "metadata": {},
   "source": [
    "Step 1 ‚Äì Convert Columns to Correct Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90095382",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flights_bronze[\"checked_bags\"] = pd.to_numeric(df_flights_bronze[\"checked_bags\"], errors=\"coerce\")\n",
    "df_flights_bronze[\"base_fare_usd\"] = pd.to_numeric(df_flights_bronze[\"base_fare_usd\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646d1bf6",
   "metadata": {},
   "source": [
    "Step 2 ‚Äì Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bea04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nulls\n",
    "df_flights_bronze.isna().sum()\n",
    "\n",
    "# Drop rows missing critical fields\n",
    "df_flights_bronze = df_flights_bronze.dropna(subset=[\"trip_id\", \"checked_bags\", \"base_fare_usd\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7434119b",
   "metadata": {},
   "source": [
    "### üè® Data Preparation ‚Äì `hotels` Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25a3412",
   "metadata": {},
   "source": [
    "In the `hotels` table, we focus on ensuring that time and price fields are correctly formatted and that missing values are handled. This is especially important for calculating `nights` from `check_in_time` and `check_out_time`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf4e896",
   "metadata": {},
   "source": [
    "Step 1 ‚Äì Convert Columns to Correct Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab575a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hotels_bronze[\"nights\"] = pd.to_numeric(df_hotels_bronze[\"nights\"], errors=\"coerce\")\n",
    "df_hotels_bronze[\"hotel_per_room_usd\"] = pd.to_numeric(df_hotels_bronze[\"hotel_per_room_usd\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1887e554",
   "metadata": {},
   "source": [
    "Step 2 ‚Äì Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78f78fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nulls\n",
    "df_hotels_bronze.isna().sum()\n",
    "\n",
    "# Drop rows with missing trip_id or calculated nights\n",
    "df_hotels_bronze = df_hotels_bronze.dropna(subset=[\"trip_id\", \"nights\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eed5986",
   "metadata": {},
   "source": [
    "## üíæ Save Silver Tables for Manual Upload to AWS S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94631ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Silver DataFrames (copies of bronze, after cleaning)\n",
    "df_flights_silver = df_flights_bronze\n",
    "df_hotels_silver = df_hotels_bronze\n",
    "df_sessions_silver = df_sessions_bronze\n",
    "df_users_silver = df_users_bronze\n",
    "\n",
    "# Folder to save locally before manual S3 upload\n",
    "silver_local_path = \"silver_exports/\"\n",
    "os.makedirs(silver_local_path, exist_ok=True)\n",
    "\n",
    "# Tables to save\n",
    "tables = {\n",
    "    \"flights_silver\": df_flights_silver,\n",
    "    \"users_silver\": df_users_silver,\n",
    "    \"hotels_silver\": df_hotels_silver,\n",
    "    \"sessions_silver\": df_sessions_silver\n",
    "}\n",
    "\n",
    "# Save each table as CSV locally\n",
    "for name, df in tables.items():\n",
    "    try:\n",
    "        path = os.path.join(silver_local_path, f\"{name}.csv\")\n",
    "        df.to_csv(path, index=False)\n",
    "        print(f\"‚úÖ Exported: {path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in {name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d15ae4",
   "metadata": {},
   "source": [
    "## üíæ Gold Level Preparation & Save Gold Tables for Manual Upload to AWS S3 Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda18629",
   "metadata": {},
   "source": [
    "Before aggregating features and clustering, we filter the silver data to include only users who meet the cohort condition defined during EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15953aa9",
   "metadata": {},
   "source": [
    "### üìé Filter Cohort ‚Äì Users with ‚â• 7 Sessions Since Jan 4, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652abd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Filter sessions since January 4, 2023\n",
    "df_sessions_silver[\"session_start\"] = pd.to_datetime(df_sessions_silver[\"session_start\"])\n",
    "recent_sessions = df_sessions_silver[df_sessions_silver[\"session_start\"] >= \"2023-01-04\"]\n",
    "\n",
    "# 2. Count sessions per user and select those with ‚â• 7\n",
    "session_counts = recent_sessions[\"user_id\"].value_counts()\n",
    "eligible_user_ids = session_counts[session_counts >= 7].index\n",
    "\n",
    "# 3. Filter all silver tables to include only eligible users\n",
    "df_sessions_silver = df_sessions_silver[df_sessions_silver[\"user_id\"].isin(eligible_user_ids)]\n",
    "df_users_silver = df_users_silver[df_users_silver[\"user_id\"].isin(eligible_user_ids)]\n",
    "\n",
    "# 4. Keep only trips linked to eligible users for hotel/flight data\n",
    "valid_trip_ids = df_sessions_silver[\"trip_id\"].dropna().unique()\n",
    "df_flights_silver = df_flights_silver[df_flights_silver[\"trip_id\"].isin(valid_trip_ids)]\n",
    "df_hotels_silver = df_hotels_silver[df_hotels_silver[\"trip_id\"].isin(valid_trip_ids)]\n",
    "\n",
    "print(f\"‚úÖ Filtered to cohort: {len(eligible_user_ids)} users with ‚â• 7 sessions since 2023-01-04.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9c2a1988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 587 entries, 1829 to 5397615\n",
      "Data columns (total 13 columns):\n",
      " #   Column                  Non-Null Count  Dtype         \n",
      "---  ------                  --------------  -----         \n",
      " 0   session_id              587 non-null    object        \n",
      " 1   user_id                 587 non-null    int64         \n",
      " 2   trip_id                 587 non-null    object        \n",
      " 3   session_start           587 non-null    datetime64[ns]\n",
      " 4   flight_discount         587 non-null    bool          \n",
      " 5   hotel_discount          587 non-null    bool          \n",
      " 6   flight_discount_amount  587 non-null    float64       \n",
      " 7   hotel_discount_amount   587 non-null    float64       \n",
      " 8   flight_booked           587 non-null    bool          \n",
      " 9   hotel_booked            587 non-null    bool          \n",
      " 10  page_clicks             587 non-null    int64         \n",
      " 11  cancellation            587 non-null    bool          \n",
      " 12  used_any_discount       587 non-null    bool          \n",
      "dtypes: bool(6), datetime64[ns](1), float64(2), int64(2), object(2)\n",
      "memory usage: 40.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_sessions_silver.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f15cd80",
   "metadata": {},
   "source": [
    "üü° Export Gold Layer ‚Äì Final User-Cohort Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13343b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Gold DataFrames (filtered for cohort and ready for clustering)\n",
    "df_flights_gold = df_flights_silver\n",
    "df_hotels_gold = df_hotels_silver\n",
    "df_sessions_gold = df_sessions_silver\n",
    "df_users_gold = df_users_silver\n",
    "\n",
    "# Folder to save locally before manual S3 upload\n",
    "gold_local_path = \"gold_exports/\"\n",
    "os.makedirs(gold_local_path, exist_ok=True)\n",
    "\n",
    "# Tables to save\n",
    "tables = {\n",
    "    \"flights_gold\": df_flights_gold,\n",
    "    \"users_gold\": df_users_gold,\n",
    "    \"hotels_gold\": df_hotels_gold,\n",
    "    \"sessions_gold\": df_sessions_gold\n",
    "}\n",
    "\n",
    "# Save each table as CSV locally\n",
    "for name, df in tables.items():\n",
    "    try:\n",
    "        path = os.path.join(gold_local_path, f\"{name}.csv\")\n",
    "        df.to_csv(path, index=False)\n",
    "        print(f\"‚úÖ Exported: {path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in {name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791ea5c2",
   "metadata": {},
   "source": [
    "# **Customer Segmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e626c24c",
   "metadata": {},
   "source": [
    "Now that the data is cleaned and all perk-relevant features have been engineered, we begin the segmentation phase.\n",
    "\n",
    "The goal is to group customers based on their behavior and assign the most suitable perk to each group.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb73b11",
   "metadata": {},
   "source": [
    "### ‚úÖ Step Overview\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d26e10",
   "metadata": {},
   "source": [
    "1. **Aggregate metrics at user level**  \n",
    "   - Calculate behavioral features (e.g., number of sessions, cancellation rate, discount usage)\n",
    "\n",
    "2. **Standardize features for clustering**  \n",
    "   - Normalize or scale numeric values (e.g., MinMaxScaler)\n",
    "\n",
    "3. **Apply clustering algorithm**  \n",
    "   - Use unsupervised learning (e.g., K-Means or DBSCAN) to form customer groups\n",
    "\n",
    "4. **Explore and interpret the clusters**  \n",
    "   - Analyze cluster composition to understand behavioral patterns\n",
    "\n",
    "5. **Assign best-fitting perk to each group**  \n",
    "   - Match perk logic to dominant behavior in each cluster\n",
    "\n",
    "---\n",
    "\n",
    "The outcome of this step will be:\n",
    "- A set of behaviorally meaningful user segments\n",
    "- Each segment matched to a perk based on its collective characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce12657",
   "metadata": {},
   "source": [
    "### üìä Step 1 ‚Äì User-Level Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee8395",
   "metadata": {},
   "source": [
    "To segment customers meaningfully, we first create a single user-level DataFrame that aggregates all relevant behavioral metrics from the cleaned `silver` tables.\n",
    "\n",
    "These features will serve as input for clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862fe0ef",
   "metadata": {},
   "source": [
    "‚úÖ Features to Aggregate Per User\n",
    "\n",
    "| Feature                     | Source Table        | Description                                                                 |\n",
    "|-----------------------------|---------------------|-----------------------------------------------------------------------------|\n",
    "| `total_sessions`           | sessions_silver     | Total number of sessions per user                                           |\n",
    "| `cancellation_rate`        | sessions_silver     | Share of sessions marked as cancellations                                   |\n",
    "| `discount_usage_rate`      | sessions_silver     | Share of sessions where any discount was applied                            |\n",
    "| `total_nights`             | hotels_silver       | Total number of nights across all hotel bookings                            |\n",
    "| `total_checked_bags`       | flights_silver      | Total number of checked bags across all flights                             |\n",
    "| `total_base_fare`          | flights_silver      | Sum of base flight fares ‚Äî indicates price sensitivity or booking class     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6908cb6",
   "metadata": {},
   "source": [
    "#### üì¶ Aggregation Code ‚Äì Create `df_user_features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ec6db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add helper column: True if any discount was used in session\n",
    "df_sessions_gold[\"used_any_discount\"] = df_sessions_gold[\"flight_discount\"] | df_sessions_gold[\"hotel_discount\"]\n",
    "\n",
    "# Now aggregate cleanly\n",
    "sessions_agg = df_sessions_gold.groupby(\"user_id\").agg(\n",
    "    total_sessions=(\"session_id\", \"count\"),\n",
    "    cancellation_rate=(\"cancellation\", \"mean\"),\n",
    "    discount_usage_rate=(\"used_any_discount\", \"mean\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b76a2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prepare sessions ---\n",
    "# Add helper column: True if user used any discount (flight or hotel)\n",
    "df_sessions_gold.loc[:, \"used_any_discount\"] = (\n",
    "    df_sessions_gold[\"flight_discount\"] | df_sessions_gold[\"hotel_discount\"]\n",
    ")\n",
    "\n",
    "# Aggregate session-based metrics\n",
    "sessions_agg = df_sessions_gold.groupby(\"user_id\").agg(\n",
    "    total_sessions=(\"session_id\", \"count\"),\n",
    "    cancellation_rate=(\"cancellation\", \"mean\"),\n",
    "    discount_usage_rate=(\"used_any_discount\", \"mean\")\n",
    ")\n",
    "\n",
    "# --- Prepare hotels ---\n",
    "hotels_agg = df_hotels_gold.groupby(\"trip_id\")[\"nights\"].sum().reset_index()\n",
    "hotels_sessions = df_sessions_gold[[\"user_id\", \"trip_id\"]].drop_duplicates()\n",
    "hotels_joined = hotels_sessions.merge(hotels_agg, on=\"trip_id\", how=\"left\")\n",
    "hotel_user_agg = hotels_joined.groupby(\"user_id\")[\"nights\"].sum().rename(\"total_nights\")\n",
    "\n",
    "# --- Prepare flights ---\n",
    "flights_agg = df_flights_gold.groupby(\"trip_id\").agg(\n",
    "    total_checked_bags=(\"checked_bags\", \"sum\"),\n",
    "    total_base_fare=(\"base_fare_usd\", \"sum\")\n",
    ").reset_index()\n",
    "flights_sessions = df_sessions_gold[[\"user_id\", \"trip_id\"]].drop_duplicates()\n",
    "flights_joined = flights_sessions.merge(flights_agg, on=\"trip_id\", how=\"left\")\n",
    "flight_user_agg = flights_joined.groupby(\"user_id\").agg(\n",
    "    total_checked_bags=(\"total_checked_bags\", \"sum\"),\n",
    "    total_base_fare=(\"total_base_fare\", \"sum\")\n",
    ")\n",
    "\n",
    "# --- Merge all user-level features ---\n",
    "df_user_features = (\n",
    "    sessions_agg\n",
    "    .join(hotel_user_agg, how=\"left\")\n",
    "    .join(flight_user_agg, how=\"left\")\n",
    "    .fillna(0)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(\"‚úÖ User-level features aggregated.\")\n",
    "df_user_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff8a38d",
   "metadata": {},
   "source": [
    "### üßÆ Step 2 ‚Äì Standardize Features for Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa6cf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df_user_features.drop(columns=[\"user_id\", \"cluster\"]).corr(), annot=True, cmap=\"YlGnBu\")\n",
    "plt.title(\"Correlation Matrix ‚Äì User-Level Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ecab4e",
   "metadata": {},
   "source": [
    "Clustering algorithms like K-Means are sensitive to feature scales. We use `MinMaxScaler` to bring all values into a uniform [0, 1] range, ensuring equal weight for each feature during distance calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45727d7c",
   "metadata": {},
   "source": [
    " ‚úÖ Features to Scale\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647fe96e",
   "metadata": {},
   "source": [
    "\n",
    "- `total_sessions`  \n",
    "- `cancellation_rate`  \n",
    "- `discount_usage_rate`  \n",
    "- `total_nights`  \n",
    "- `total_checked_bags`  \n",
    "- `total_base_fare`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e386d084",
   "metadata": {},
   "source": [
    "We apply `MinMaxScaler` from `sklearn.preprocessing` and store the results in a new DataFrame for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9369fb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Select features to scale\n",
    "features_to_scale = [\n",
    "    \"total_sessions\",\n",
    "    \"cancellation_rate\",\n",
    "    \"discount_usage_rate\",\n",
    "    \"total_nights\",\n",
    "    \"total_checked_bags\",\n",
    "    \"total_base_fare\"\n",
    "]\n",
    "\n",
    "# Scale\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(df_user_features[features_to_scale])\n",
    "\n",
    "# Store scaled values in new DataFrame with user_id\n",
    "df_scaled = pd.DataFrame(X_scaled, columns=features_to_scale)\n",
    "df_scaled[\"user_id\"] = df_user_features[\"user_id\"].values\n",
    "\n",
    "print(\"‚úÖ Scaled features ready for clustering.\")\n",
    "df_scaled.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfd90c6",
   "metadata": {},
   "source": [
    "### üîç Step 3 ‚Äì Clustering the Users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32593bdc",
   "metadata": {},
   "source": [
    "‚úÖ What we‚Äôll do in this step:\n",
    "\n",
    "- Decide how many clusters to try (e.g. k=3, k=4, k=5)\n",
    "\n",
    "- Fit the KMeans model on df_scaled (without user_id)\n",
    "\n",
    "- Store the assigned cluster label back in df_user_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e42edb",
   "metadata": {},
   "source": [
    "#### üìà Determine Optimal `k` ‚Äì Elbow Curve for K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53db0f1",
   "metadata": {},
   "source": [
    "We use the elbow method to plot inertia (clustering error) for a range of cluster counts.  \n",
    "The \"elbow point\" indicates a good balance between cluster compactness and generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da59cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Drop user_id column before clustering\n",
    "X = df_scaled.drop(columns=[\"user_id\"])\n",
    "\n",
    "# Try different k values\n",
    "inertia = []\n",
    "k_range = range(1, 11)\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=\"auto\")\n",
    "    kmeans.fit(X)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot elbow curve\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(k_range, inertia, marker=\"o\")\n",
    "plt.title(\"Elbow Curve ‚Äì K-Means Inertia vs. Cluster Count\")\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c73dbed",
   "metadata": {},
   "source": [
    "#### üß© Step 4 ‚Äì Apply KMeans Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517af197",
   "metadata": {},
   "source": [
    "We apply KMeans clustering with `k = 4` and assign each user a cluster label for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a83695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Drop user_id for clustering\n",
    "X = df_scaled.drop(columns=[\"user_id\"])\n",
    "\n",
    "# Apply KMeans\n",
    "kmeans = KMeans(n_clusters=4, random_state=42, n_init=\"auto\")\n",
    "df_scaled[\"cluster\"] = kmeans.fit_predict(X)\n",
    "\n",
    "# Add cluster to original user feature DataFrame\n",
    "df_user_features[\"cluster\"] = df_scaled[\"cluster\"]\n",
    "\n",
    "# Reduce to 2D for plotting\n",
    "pca = PCA(n_components=2)\n",
    "components = pca.fit_transform(X)\n",
    "\n",
    "# Plot clusters\n",
    "plt.figure(figsize=(8, 5))\n",
    "scatter = plt.scatter(components[:, 0], components[:, 1], c=df_scaled[\"cluster\"], cmap=\"Set2\", s=30)\n",
    "plt.title(\"User Segmentation ‚Äì PCA Projection (k=4)\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.grid(True)\n",
    "plt.legend(*scatter.legend_elements(), title=\"Cluster\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b2d31d",
   "metadata": {},
   "source": [
    "### üéØ Step 5 ‚Äì Interpret Clusters & Assign Perks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41677000",
   "metadata": {},
   "source": [
    "We now examine each cluster‚Äôs average behavior to determine which **perk** fits best.  \n",
    "This is based on aggregated metrics like discount usage, cancellations, and travel activity.\n",
    "\n",
    "We calculate mean feature values for each cluster to detect dominant patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03df0556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average behavior per cluster\n",
    "cluster_summary = df_user_features.groupby(\"cluster\").mean(numeric_only=True)\n",
    "cluster_summary.style.background_gradient(cmap=\"YlGnBu\").format(\"{:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d57d99",
   "metadata": {},
   "source": [
    "üß† Cluster Interpretation & Perk Assignment\n",
    "\n",
    "| Cluster | Behavioral Summary                                                                 | Assigned Perk                  |\n",
    "|---------|-------------------------------------------------------------------------------------|--------------------------------|\n",
    "| 0       | High discount usage, low cancellations, active in both flights and hotels          | üéÅ Exclusive Discounts         |\n",
    "| 1       | Low spenders, few sessions, little engagement                                      | üß≥ Free Checked Bag            |\n",
    "| 2       | High cancellation rate, medium session volume                                      | ‚ùå No Cancellation Fees        |\n",
    "| 3       | Frequent hotel+flight usage, long nights, high fares                               | üè® 1 Night Free with Flight    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58c6716",
   "metadata": {},
   "source": [
    "## ü§ñ Machine Learning ‚Äì Predicting Cluster Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b440ac6",
   "metadata": {},
   "source": [
    "We train a classifier to predict user clusters from behavioral features.  \n",
    "This allows perk recommendations to be extended to new users in a scalable, supervised way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec997438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Step 1 ‚Äì Features (X) and target (y)\n",
    "X = df_user_features[[\n",
    "    \"total_sessions\",\n",
    "    \"cancellation_rate\",\n",
    "    \"discount_usage_rate\",\n",
    "    \"total_nights\",\n",
    "    \"total_checked_bags\",\n",
    "    \"total_base_fare\"\n",
    "]]\n",
    "\n",
    "y = df_user_features[\"cluster\"]\n",
    "\n",
    "# Step 2 ‚Äì Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Step 3 ‚Äì Train model\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 4 ‚Äì Evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"‚úÖ Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"üß© Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mastery-project)",
   "language": "python",
   "name": "mastery-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
