{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "647d8ba1",
   "metadata": {},
   "source": [
    "# <span style=\"color:#e67e22;\">◼</span> **Project Overview**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24faf25",
   "metadata": {},
   "source": [
    "\n",
    "This notebook is part of *Master Project 2025*, which focuses on assigning personalized perks to users based on their behavior on the travel platform. The analysis is entirely behavior-driven and deliberately excludes demographic or personal information. The ultimate goal is to segment users into meaningful groups and link each group with the most relevant perk.\n",
    "\n",
    "Only perks that are supported by the available data are considered. These include:\n",
    "\n",
    "- ✅ **Free checked bag**  \n",
    "- ✅ **No cancellation fees**  \n",
    "- ✅ **Exclusive discounts**  \n",
    "- ✅ **One night free hotel with flight**  \n",
    "- ❌ *Free hotel meal* (excluded due to missing data support)\n",
    "\n",
    "This notebook covers the first steps of the analysis pipeline: loading and previewing raw data, selecting relevant variables, cleaning and transforming the datasets, and generating user-level features. These steps prepare the data for clustering, which will be used to assign the most suitable perk to each user segment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2611cc",
   "metadata": {},
   "source": [
    "# <span style=\"color:#e67e22;\">◼</span> **EDA & Feature Engneering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45899623",
   "metadata": {},
   "source": [
    "## <span style=\"color:#1f4e79;\">◼</span> Load Data from AWS S3 Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f830df5c",
   "metadata": {},
   "source": [
    "No accesdetails needed for this Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99c080d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_flights_bronze():\n",
    "    url = \"https://lakehouse-masteryproject-2025.s3.eu-north-1.amazonaws.com/bronze/public_flights_export_2025-03-31_134734.csv\"\n",
    "    return pd.read_csv(url)\n",
    "\n",
    "def load_hotels_bronze():\n",
    "    url = \"https://lakehouse-masteryproject-2025.s3.eu-north-1.amazonaws.com/bronze/public_hotels_export_2025-03-31_171805.csv\"\n",
    "    return pd.read_csv(url)\n",
    "\n",
    "def load_sessions_bronze():\n",
    "    url = \"https://lakehouse-masteryproject-2025.s3.eu-north-1.amazonaws.com/bronze/public_sessions_export_2025-03-31_221253.csv\"\n",
    "    return pd.read_csv(url)\n",
    "\n",
    "def load_users_bronze():\n",
    "    url = \"https://lakehouse-masteryproject-2025.s3.eu-north-1.amazonaws.com/bronze/public_users_export_2025-04-01_101058.csv\"\n",
    "    return pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ab82064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Flight, hotel, session and user data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "df_flights_bronze = load_flights_bronze()\n",
    "df_hotels_bronze = load_hotels_bronze()\n",
    "df_sessions_bronze = load_sessions_bronze()\n",
    "df_users_bronze = load_users_bronze()\n",
    "\n",
    "print(\"✅ Flight, hotel, session and user data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3084a73b",
   "metadata": {},
   "source": [
    "## <span style=\"color:#1f4e79;\">◼</span> Reducing Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5abaf1",
   "metadata": {},
   "source": [
    "The next step is to reduce the columns to only those needed to validate the hypotheses behind the defined perks. All other columns are excluded unless they are required to calculate new features (e.g., `nights` for trip duration) or to support the interpretation of results.\n",
    "\n",
    "**Personalization Scope (Project Context)**\n",
    "\n",
    "- In this project, personalization is based exclusively on **individual user behavior** observed within the TravelTide platform. This includes patterns such as discount usage, booking behavior, and cancellation frequency.\n",
    "\n",
    "- Demographic or group-level attributes (e.g. family status, number of travelers, or room count) are not considered. The goal is to assign each user the perk most relevant to **how they interact** with the platform — not who they are or who they travel with.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699efc82",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4b5320;\">◼</span> Reducing Columns – `users` Table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f304530a",
   "metadata": {},
   "source": [
    "\n",
    "For the `users` table, we keep only the columns required to support the behavioral logic behind the defined perks. Since personalization in this project is based purely on **individual interaction behavior**, we exclude all demographic and group-related attributes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23bfb5e",
   "metadata": {},
   "source": [
    "| Column         | Description                                                           | Keep? |\n",
    "|----------------|------------------------------------------------------------------------|:-----:|\n",
    "| `user_id`      | Required to join with sessions and flights                            | ✅    |\n",
    "| `birthdate`    | Age not relevant to behavior-based logic                              | ❌    |\n",
    "| `has_children` | Not used for any defined perk — group/family-related                  | ❌    |\n",
    "| `gender`       | Not tied to any perk                                                  | ❌    |\n",
    "| `married`      | Not tied to any perk                                                  | ❌    |\n",
    "| `home_country` | Not required for perk logic                                           | ❌    |\n",
    "| `home_city`    | Too granular for this scope                                           | ❌    |\n",
    "| `home_airport` | Not relevant for current perks                                        | ❌    |\n",
    "| `sign_up_date` | Not used in perk logic                                                | ❌    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "766fcedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_id",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "272c5c40-d20a-425d-b925-d052de65a4fe",
       "rows": [
        [
         "0",
         "841803"
        ],
        [
         "1",
         "841804"
        ],
        [
         "2",
         "841805"
        ],
        [
         "3",
         "841806"
        ],
        [
         "4",
         "841807"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>841803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>841804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>841805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>841806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>841807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id\n",
       "0   841803\n",
       "1   841804\n",
       "2   841805\n",
       "3   841806\n",
       "4   841807"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users_bronze = df_sessions_bronze[\n",
    "    ['user_id']\n",
    "]\n",
    "df_users_bronze.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c163e215",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4b5320;\">◼</span> Reducing Columns – `sessions` Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040efc87",
   "metadata": {},
   "source": [
    "\n",
    "The `sessions` table is the most important source for behavioral signals in this project. We retain only the columns directly required to support the five defined perks or essential to filtering and joining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196e8923",
   "metadata": {},
   "source": [
    "| Column                   | Description                                                                 | Keep? |\n",
    "|--------------------------|-----------------------------------------------------------------------------|:-----:|\n",
    "| `session_id`             | Needed to count sessions per user (7+ sessions filter)                      | ✅    |\n",
    "| `user_id`                | Required to join with users                                                 | ✅    |\n",
    "| `trip_id`                | Required to connect to flights and hotels                                   | ✅    |\n",
    "| `session_start`          | Used to filter sessions after Jan 4, 2023                                   | ✅    |\n",
    "| `flight_discount`        | Supports the \"exclusive discounts\" perk                                     | ✅    |\n",
    "| `hotel_discount`         | Supports the \"exclusive discounts\" perk                                     | ✅    |\n",
    "| `flight_discount_amount` | Captures price sensitivity for flight discounts                             | ✅    |\n",
    "| `hotel_discount_amount`  | Captures price sensitivity for hotel discounts                              | ✅    |\n",
    "| `flight_booked`          | Required to understand booking behavior                                     | ✅    |\n",
    "| `hotel_booked`           | Required to validate hotel+flight pairing                                   | ✅    |\n",
    "| `page_clicks`            | Indicates user engagement — helps understand interaction effort             | ✅    |\n",
    "| `cancellation`           | Directly supports the \"no cancellation fees\" perk                           | ✅    |\n",
    "| `session_end`            | Not required for any of the defined perks                                   | ❌    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13f460d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "session_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "user_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "trip_id",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "session_start",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "flight_discount",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "hotel_discount",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "flight_discount_amount",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hotel_discount_amount",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flight_booked",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "hotel_booked",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "page_clicks",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cancellation",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "71f3dfc7-ddfc-449f-9e82-d0b3d4193803",
       "rows": [
        [
         "0",
         "841803-95c93659053948049c73106ffdcf4df6",
         "841803",
         "841803-31d33d39b08f477bb8d9dd3b0dcbf1d3",
         "2023-05-17 19:40:00",
         "False",
         "False",
         null,
         null,
         "True",
         "True",
         "30",
         "False"
        ],
        [
         "1",
         "841804-bf1bfe452c4d4372b04d9612134006e7",
         "841804",
         null,
         "2023-05-17 22:40:00",
         "False",
         "False",
         null,
         null,
         "False",
         "False",
         "9",
         "False"
        ],
        [
         "2",
         "841805-70d695ee6540481bae7750e368c10443",
         "841805",
         "841805-506d17340ffa41659736fd258138a9b5",
         "2023-05-17 21:10:00",
         "False",
         "False",
         null,
         null,
         "True",
         "True",
         "24",
         "False"
        ],
        [
         "3",
         "841806-a03ac981d1c847979765669ca871a0cb",
         "841806",
         null,
         "2023-05-17 21:49:00",
         "True",
         "True",
         "0.2",
         "0.2",
         "False",
         "False",
         "42",
         "False"
        ],
        [
         "4",
         "841807-4febb023cd414a6196fc026af1928bfb",
         "841807",
         null,
         "2023-05-17 20:28:00",
         "False",
         "False",
         null,
         null,
         "False",
         "False",
         "4",
         "False"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>session_start</th>\n",
       "      <th>flight_discount</th>\n",
       "      <th>hotel_discount</th>\n",
       "      <th>flight_discount_amount</th>\n",
       "      <th>hotel_discount_amount</th>\n",
       "      <th>flight_booked</th>\n",
       "      <th>hotel_booked</th>\n",
       "      <th>page_clicks</th>\n",
       "      <th>cancellation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>841803-95c93659053948049c73106ffdcf4df6</td>\n",
       "      <td>841803</td>\n",
       "      <td>841803-31d33d39b08f477bb8d9dd3b0dcbf1d3</td>\n",
       "      <td>2023-05-17 19:40:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>841804-bf1bfe452c4d4372b04d9612134006e7</td>\n",
       "      <td>841804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-17 22:40:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>841805-70d695ee6540481bae7750e368c10443</td>\n",
       "      <td>841805</td>\n",
       "      <td>841805-506d17340ffa41659736fd258138a9b5</td>\n",
       "      <td>2023-05-17 21:10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>841806-a03ac981d1c847979765669ca871a0cb</td>\n",
       "      <td>841806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-17 21:49:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>42</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>841807-4febb023cd414a6196fc026af1928bfb</td>\n",
       "      <td>841807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-17 20:28:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                session_id  user_id  \\\n",
       "0  841803-95c93659053948049c73106ffdcf4df6   841803   \n",
       "1  841804-bf1bfe452c4d4372b04d9612134006e7   841804   \n",
       "2  841805-70d695ee6540481bae7750e368c10443   841805   \n",
       "3  841806-a03ac981d1c847979765669ca871a0cb   841806   \n",
       "4  841807-4febb023cd414a6196fc026af1928bfb   841807   \n",
       "\n",
       "                                   trip_id        session_start  \\\n",
       "0  841803-31d33d39b08f477bb8d9dd3b0dcbf1d3  2023-05-17 19:40:00   \n",
       "1                                      NaN  2023-05-17 22:40:00   \n",
       "2  841805-506d17340ffa41659736fd258138a9b5  2023-05-17 21:10:00   \n",
       "3                                      NaN  2023-05-17 21:49:00   \n",
       "4                                      NaN  2023-05-17 20:28:00   \n",
       "\n",
       "   flight_discount  hotel_discount  flight_discount_amount  \\\n",
       "0            False           False                     NaN   \n",
       "1            False           False                     NaN   \n",
       "2            False           False                     NaN   \n",
       "3             True            True                     0.2   \n",
       "4            False           False                     NaN   \n",
       "\n",
       "   hotel_discount_amount  flight_booked  hotel_booked  page_clicks  \\\n",
       "0                    NaN           True          True           30   \n",
       "1                    NaN          False         False            9   \n",
       "2                    NaN           True          True           24   \n",
       "3                    0.2          False         False           42   \n",
       "4                    NaN          False         False            4   \n",
       "\n",
       "   cancellation  \n",
       "0         False  \n",
       "1         False  \n",
       "2         False  \n",
       "3         False  \n",
       "4         False  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sessions_bronze = df_sessions_bronze[\n",
    "    [\n",
    "        \"session_id\", \"user_id\", \"trip_id\", \"session_start\",\n",
    "        \"flight_discount\", \"hotel_discount\",\n",
    "        \"flight_discount_amount\", \"hotel_discount_amount\",\n",
    "        \"flight_booked\", \"hotel_booked\",\n",
    "        \"page_clicks\", \"cancellation\"\n",
    "    ]\n",
    "]\n",
    "df_sessions_bronze.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad837ed0",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4b5320;\">◼</span> Reducing Columns – `flights` Table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f7a8e8",
   "metadata": {},
   "source": [
    "\n",
    "We retain only the columns that are directly required to support perk validation. Columns related to destinations, time, or route details are excluded, as none of the five defined perks depend on them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afc5d83",
   "metadata": {},
   "source": [
    "| Column                   | Description                                                                                  |\n",
    "|--------------------------|----------------------------------------------------------------------------------------------|\n",
    "| `trip_id`                | ✅ Required to join with sessions                                                             |\n",
    "| `checked_bags`           | ✅ Directly supports the \"free checked bag\" perk                                              |\n",
    "| `base_fare_usd`          | ✅ Supports the \"exclusive discounts\" perk by capturing price sensitivity                     |\n",
    "| `trip_airline`           | ❌ Not needed for current perks                                                               |\n",
    "| `origin_airport`         | ❌ Not required for any defined perk                                                          |\n",
    "| `destination`            | ❌ Not required for any defined perk                                                          |\n",
    "| `destination_airport`    | ❌ Redundant and not perk-related                                                             |\n",
    "| `seats`                  | ❌ Not needed for defined perks                                                               |\n",
    "| `return_flight_booked`   | ❌ Not used for any current perk                                                              |\n",
    "| `departure_time`         | ❌ Not used for any current perk                                                              |\n",
    "| `return_time`            | ❌ Not used for any current perk                                                              |\n",
    "| `destination_airport_lat`| ❌ Mapping only — not used in perks                                                           |\n",
    "| `destination_airport_lon`| ❌ Mapping only — not used in perks                                                           |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1128ebaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "trip_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "checked_bags",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "base_fare_usd",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "be4e802f-291d-4328-97ba-20393ed51cc0",
       "rows": [
        [
         "0",
         "693092-7b8767746abd45219ed468d58da9f702",
         "0",
         "479.31"
        ],
        [
         "1",
         "693124-1032149a9e01427da914b17ce6ef1926",
         "0",
         "575.78"
        ],
        [
         "2",
         "693149-0fdb31c7dc114a4d8a318f0feada365c",
         "0",
         "336.72"
        ],
        [
         "3",
         "693169-d120c3721d0b4bcca278639c981e4322",
         "0",
         "295.37"
        ],
        [
         "4",
         "693181-f4a2363db0ee452f8ac8c0fe3d4ef0ad",
         "1",
         "694.26"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>checked_bags</th>\n",
       "      <th>base_fare_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>693092-7b8767746abd45219ed468d58da9f702</td>\n",
       "      <td>0</td>\n",
       "      <td>479.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>693124-1032149a9e01427da914b17ce6ef1926</td>\n",
       "      <td>0</td>\n",
       "      <td>575.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>693149-0fdb31c7dc114a4d8a318f0feada365c</td>\n",
       "      <td>0</td>\n",
       "      <td>336.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693169-d120c3721d0b4bcca278639c981e4322</td>\n",
       "      <td>0</td>\n",
       "      <td>295.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>693181-f4a2363db0ee452f8ac8c0fe3d4ef0ad</td>\n",
       "      <td>1</td>\n",
       "      <td>694.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   trip_id  checked_bags  base_fare_usd\n",
       "0  693092-7b8767746abd45219ed468d58da9f702             0         479.31\n",
       "1  693124-1032149a9e01427da914b17ce6ef1926             0         575.78\n",
       "2  693149-0fdb31c7dc114a4d8a318f0feada365c             0         336.72\n",
       "3  693169-d120c3721d0b4bcca278639c981e4322             0         295.37\n",
       "4  693181-f4a2363db0ee452f8ac8c0fe3d4ef0ad             1         694.26"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flights_bronze = df_flights_bronze[\n",
    "    [\"trip_id\", \"checked_bags\", \"base_fare_usd\"]\n",
    "]\n",
    "\n",
    "df_flights_bronze.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a288e412",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4b5320;\">◼</span> Reducing Columns – `hotels` Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b865abe",
   "metadata": {},
   "source": [
    "In the `hotels` table, we only keep columns that are directly needed to validate the defined perks. All other fields, such as room count, hotel brand, or check-in/out times, are excluded since they are not required for any of the five perks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0add020e",
   "metadata": {},
   "source": [
    "| Column               | Description                                                                                   |\n",
    "|----------------------|-----------------------------------------------------------------------------------------------|\n",
    "| `trip_id`            | ✅ Required to join hotels with sessions and flights                                          |\n",
    "| `nights`             | ✅ Required to validate the \"1 night free hotel with flight\" perk                             |\n",
    "| `hotel_per_room_usd` | ✅ Supports the \"exclusive discounts\" perk by capturing price sensitivity                      |\n",
    "| `hotel_name`         | ❌ Not needed for any defined perk                                                             |\n",
    "| `rooms`              | ❌ Not used for any current perk                                                               |\n",
    "| `check_in_time`      | ❌ Not required for any of the defined perks                                                   |\n",
    "| `check_out_time`     | ❌ Not required — duration is already captured by `nights`                                     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a595d7",
   "metadata": {},
   "source": [
    "Instead of relying on the nights column from the dataset, we calculate it ourselves based on actual hote logic: check-in time, check-out time, and a grace period. A late checkout may result in an additional night being counted. This behavior is more realistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7dba010d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hotels_bronze = df_hotels_bronze.drop(columns=[\"nights\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b0dd999",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "# Hotel rules\n",
    "CHECKIN_TIME = datetime.strptime(\"15:00\", \"%H:%M\").time()\n",
    "CHECKOUT_TIME = datetime.strptime(\"11:00\", \"%H:%M\").time()\n",
    "GRACE_PERIOD = timedelta(hours=1)  # 1-hour grace period\n",
    "\n",
    "# Convert check-in/out columns to datetime first\n",
    "df_hotels_bronze[\"check_in_time\"] = pd.to_datetime(df_hotels_bronze[\"check_in_time\"], errors=\"coerce\")\n",
    "df_hotels_bronze[\"check_out_time\"] = pd.to_datetime(df_hotels_bronze[\"check_out_time\"], errors=\"coerce\")\n",
    "\n",
    "# Function to calculate realistic nights\n",
    "def calculate_nights_realistic(row):\n",
    "    check_in = row[\"check_in_time\"]\n",
    "    check_out = row[\"check_out_time\"]\n",
    "\n",
    "    if pd.isna(check_in) or pd.isna(check_out):\n",
    "        return None\n",
    "\n",
    "    check_in_date = check_in.date()\n",
    "    check_out_date = check_out.date()\n",
    "    nights = (check_out_date - check_in_date).days\n",
    "\n",
    "    # Add 1 night if checkout was late (after grace period)\n",
    "    checkout_deadline = datetime.combine(check_out_date, CHECKOUT_TIME) + GRACE_PERIOD\n",
    "    if check_out > checkout_deadline:\n",
    "        nights += 1\n",
    "\n",
    "    return max(nights, 0)  # Ensure non-negative result\n",
    "\n",
    "# Recalculate nights column\n",
    "df_hotels_bronze[\"nights\"] = df_hotels_bronze.apply(calculate_nights_realistic, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac3c269d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "trip_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "nights",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hotel_per_room_usd",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "3bf057d2-db6d-4714-a9fe-7c8e00921fb6",
       "rows": [
        [
         "0",
         "234666-99574aa53f30402ba04bfe2f3337c566",
         "2.0",
         "226"
        ],
        [
         "1",
         "234707-4c0cfdb5ff4a4cd8bda5feed22f790d7",
         "2.0",
         "114"
        ],
        [
         "2",
         "234745-a8f944dc121c4003b16c108c9c590965",
         "4.0",
         "322"
        ],
        [
         "3",
         "234905-c1e14087ef1f4a7a8413a12ef4208135",
         "2.0",
         "228"
        ],
        [
         "4",
         "235101-cd0e752033db4f488fa75b5eb8feb2c8",
         "2.0",
         "163"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>nights</th>\n",
       "      <th>hotel_per_room_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>234666-99574aa53f30402ba04bfe2f3337c566</td>\n",
       "      <td>2.0</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>234707-4c0cfdb5ff4a4cd8bda5feed22f790d7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>234745-a8f944dc121c4003b16c108c9c590965</td>\n",
       "      <td>4.0</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>234905-c1e14087ef1f4a7a8413a12ef4208135</td>\n",
       "      <td>2.0</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>235101-cd0e752033db4f488fa75b5eb8feb2c8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   trip_id  nights  hotel_per_room_usd\n",
       "0  234666-99574aa53f30402ba04bfe2f3337c566     2.0                 226\n",
       "1  234707-4c0cfdb5ff4a4cd8bda5feed22f790d7     2.0                 114\n",
       "2  234745-a8f944dc121c4003b16c108c9c590965     4.0                 322\n",
       "3  234905-c1e14087ef1f4a7a8413a12ef4208135     2.0                 228\n",
       "4  235101-cd0e752033db4f488fa75b5eb8feb2c8     2.0                 163"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hotels_bronze = df_hotels_bronze[[\"trip_id\", \"nights\", \"hotel_per_room_usd\"]]\n",
    "\n",
    "df_hotels_bronze.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878667e9",
   "metadata": {},
   "source": [
    "## <span style=\"color:#1f4e79;\">◼</span> Parse and Standardize Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85160b71",
   "metadata": {},
   "source": [
    "Before we can assign perks or create user-level aggregations, we need to ensure that all four tables — `users`, `sessions`, `flights`, and `hotels` — are clean and consistent. This includes standardizing data types, handling missing values, and ensuring that binary and datetime fields are correctly formatted.\n",
    "\n",
    "Each table requires slightly different steps, depending on the structure of the data it contains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715da046",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4b5320;\">◼</span> Data Preparation – `users` Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412d0e13",
   "metadata": {},
   "source": [
    "The `users` table contains only two columns needed for the defined perks: `user_id` and `birthdate`. Our main goal here is to ensure `birthdate` is in datetime format so we can calculate user age if needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7402125a",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#800020;\">◼</span> Convert Columns to Correct Data Types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a93711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_bronze[\"birthdate\"] = pd.to_datetime(df_users_bronze[\"birthdate\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3ec197",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#800020;\">◼</span> Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d18e98cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nulls\n",
    "df_users_bronze.isna().sum()\n",
    "\n",
    "# Drop rows with missing user_id or birthdate\n",
    "df_users_bronze = df_users_bronze.dropna(subset=[\"user_id\", \"birthdate\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6109cc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "birthdate",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "db174105-c2f9-4db9-ae75-5185e235891f",
       "rows": [
        [
         "0",
         "0",
         "1990-01-22 00:00:00"
        ],
        [
         "1",
         "1",
         "2000-11-08 00:00:00"
        ],
        [
         "2",
         "2",
         "1992-09-21 00:00:00"
        ],
        [
         "3",
         "3",
         "1996-11-27 00:00:00"
        ],
        [
         "4",
         "4",
         "1978-01-05 00:00:00"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>birthdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1990-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2000-11-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1992-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1996-11-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1978-01-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  birthdate\n",
       "0        0 1990-01-22\n",
       "1        1 2000-11-08\n",
       "2        2 1992-09-21\n",
       "3        3 1996-11-27\n",
       "4        4 1978-01-05"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users_bronze.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4679d506",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4b5320;\">◼</span> Data Preparation – `sessions` Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64de2ae3",
   "metadata": {},
   "source": [
    "We start by preparing the `sessions` table. The main focus is on:\n",
    "\n",
    "- Ensuring correct data types (especially for datetime and boolean fields)\n",
    "- Handling missing values\n",
    "- Verifying binary logic for downstream scoring and aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc9834b",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#800020;\">◼</span> Convert Columns to Correct Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50aeb18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sessions_bronze[\"session_start\"] = pd.to_datetime(df_sessions_bronze[\"session_start\"])\n",
    "df_sessions_bronze[\"flight_discount\"] = df_sessions_bronze[\"flight_discount\"].astype(bool)\n",
    "df_sessions_bronze[\"hotel_discount\"] = df_sessions_bronze[\"hotel_discount\"].astype(bool)\n",
    "df_sessions_bronze[\"flight_booked\"] = df_sessions_bronze[\"flight_booked\"].astype(bool)\n",
    "df_sessions_bronze[\"hotel_booked\"] = df_sessions_bronze[\"hotel_booked\"].astype(bool)\n",
    "df_sessions_bronze[\"cancellation\"] = df_sessions_bronze[\"cancellation\"].astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e595a3",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#800020;\">◼</span> Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "267ba44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nulls\n",
    "df_sessions_bronze.isna().sum()\n",
    "\n",
    "# Drop sessions without user_id or trip_id, which are critical\n",
    "df_sessions_bronze = df_sessions_bronze.dropna(subset=[\"user_id\", \"trip_id\"])\n",
    "\n",
    "# Fill missing discount amounts with 0\n",
    "df_sessions_bronze[\"flight_discount_amount\"] = df_sessions_bronze[\"flight_discount_amount\"].fillna(0)\n",
    "df_sessions_bronze[\"hotel_discount_amount\"] = df_sessions_bronze[\"hotel_discount_amount\"].fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d122c54",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#800020;\">◼</span> Validate Binary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1591ec3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flight_discount [False  True]\n",
      "hotel_discount [False  True]\n",
      "flight_booked [ True False]\n",
      "hotel_booked [ True False]\n",
      "cancellation [False  True]\n"
     ]
    }
   ],
   "source": [
    "# Confirm binary fields contain only True/False\n",
    "binary_fields = [\"flight_discount\", \"hotel_discount\", \"flight_booked\", \"hotel_booked\", \"cancellation\"]\n",
    "for col in binary_fields:\n",
    "    print(col, df_sessions_bronze[col].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f4ad0e",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4b5320;\">◼</span> Data Preparation – `flights` Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8c65ee",
   "metadata": {},
   "source": [
    "In the `flights` table, we prepare the data by ensuring correct data types and handling missing values in price and baggage-related columns. Since only three columns are needed to validate the defined perks, we focus cleanup on those specifically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd23ab83",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#800020;\">◼</span> Convert Columns to Correct Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90095382",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flights_bronze[\"checked_bags\"] = pd.to_numeric(df_flights_bronze[\"checked_bags\"], errors=\"coerce\")\n",
    "df_flights_bronze[\"base_fare_usd\"] = pd.to_numeric(df_flights_bronze[\"base_fare_usd\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646d1bf6",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#800020;\">◼</span> Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1bea04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nulls\n",
    "df_flights_bronze.isna().sum()\n",
    "\n",
    "# Drop rows missing critical fields\n",
    "df_flights_bronze = df_flights_bronze.dropna(subset=[\"trip_id\", \"checked_bags\", \"base_fare_usd\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7434119b",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4b5320;\">◼</span> Data Preparation – `hotels` Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25a3412",
   "metadata": {},
   "source": [
    "In the `hotels` table, we focus on ensuring that time and price fields are correctly formatted and that missing values are handled. This is especially important for calculating `nights` from `check_in_time` and `check_out_time`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf4e896",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#800020;\">◼</span> Convert Columns to Correct Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fab575a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hotels_bronze[\"nights\"] = pd.to_numeric(df_hotels_bronze[\"nights\"], errors=\"coerce\")\n",
    "df_hotels_bronze[\"hotel_per_room_usd\"] = pd.to_numeric(df_hotels_bronze[\"hotel_per_room_usd\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1887e554",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#800020;\">◼</span> Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d78f78fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nulls\n",
    "df_hotels_bronze.isna().sum()\n",
    "\n",
    "# Drop rows with missing trip_id or calculated nights\n",
    "df_hotels_bronze = df_hotels_bronze.dropna(subset=[\"trip_id\", \"nights\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eed5986",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#800020;\">◼</span> Export Silver Tables for Manual AWS S3 Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94631ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Exported: silver_exports/flights_silver.csv\n",
      "✅ Exported: silver_exports/users_silver.csv\n",
      "✅ Exported: silver_exports/hotels_silver.csv\n",
      "✅ Exported: silver_exports/sessions_silver.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Silver DataFrames (copies of bronze, after cleaning)\n",
    "df_flights_silver = df_flights_bronze\n",
    "df_hotels_silver = df_hotels_bronze\n",
    "df_sessions_silver = df_sessions_bronze\n",
    "df_users_silver = df_users_bronze\n",
    "\n",
    "# Folder to save locally before manual S3 upload\n",
    "silver_local_path = \"silver_exports/\"\n",
    "os.makedirs(silver_local_path, exist_ok=True)\n",
    "\n",
    "# Tables to save\n",
    "tables = {\n",
    "    \"flights_silver\": df_flights_silver,\n",
    "    \"users_silver\": df_users_silver,\n",
    "    \"hotels_silver\": df_hotels_silver,\n",
    "    \"sessions_silver\": df_sessions_silver\n",
    "}\n",
    "\n",
    "# Save each table as CSV locally\n",
    "for name, df in tables.items():\n",
    "    try:\n",
    "        path = os.path.join(silver_local_path, f\"{name}.csv\")\n",
    "        df.to_csv(path, index=False)\n",
    "        print(f\"✅ Exported: {path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in {name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d15ae4",
   "metadata": {},
   "source": [
    "## <span style=\"color:#1f4e79;\">◼</span> Users with ≥ 7 Sessions Since January 4, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda18629",
   "metadata": {},
   "source": [
    "This threshold is defined in the official project guidelines. Users with fewer than 7 sessions since January 4, 2023 are excluded to ensure that only active users with sufficient interaction history are included in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "652abd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Filtered to cohort: 79 users with ≥ 7 sessions since 2023-01-04.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Filter sessions since January 4, 2023\n",
    "df_sessions_silver[\"session_start\"] = pd.to_datetime(df_sessions_silver[\"session_start\"])\n",
    "recent_sessions = df_sessions_silver[df_sessions_silver[\"session_start\"] >= \"2023-01-04\"]\n",
    "\n",
    "# 2. Count sessions per user and select those with ≥ 7\n",
    "session_counts = recent_sessions[\"user_id\"].value_counts()\n",
    "eligible_user_ids = session_counts[session_counts >= 7].index\n",
    "\n",
    "# 3. Filter all silver tables to include only eligible users\n",
    "df_sessions_silver = df_sessions_silver[df_sessions_silver[\"user_id\"].isin(eligible_user_ids)]\n",
    "df_users_silver = df_users_silver[df_users_silver[\"user_id\"].isin(eligible_user_ids)]\n",
    "\n",
    "# 4. Keep only trips linked to eligible users for hotel/flight data\n",
    "valid_trip_ids = df_sessions_silver[\"trip_id\"].dropna().unique()\n",
    "df_flights_silver = df_flights_silver[df_flights_silver[\"trip_id\"].isin(valid_trip_ids)]\n",
    "df_hotels_silver = df_hotels_silver[df_hotels_silver[\"trip_id\"].isin(valid_trip_ids)]\n",
    "\n",
    "print(f\"✅ Filtered to cohort: {len(eligible_user_ids)} users with ≥ 7 sessions since 2023-01-04.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791ea5c2",
   "metadata": {},
   "source": [
    "# <span style=\"color:#e67e22;\">◼</span> **Customer Segmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e626c24c",
   "metadata": {},
   "source": [
    "Now that the data is cleaned and all perk-relevant features have been engineered, we begin the segmentation phase. The goal is to group customers based on their behavior and assign the most suitable perk to each group.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb73b11",
   "metadata": {},
   "source": [
    "## <span style=\"color:#1f4e79;\">◼</span> Clustering Pipeline Overview\n",
    "\n",
    "To assign the most suitable perk to each user based on behavior, the following five-step clustering process is applied:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d26e10",
   "metadata": {},
   "source": [
    "1. Aggregate user-level metrics  \n",
    "   ○ Create behavioral features (e.g., sessions, cancellations, discounts)  \n",
    "\n",
    "2. Scale features for clustering  \n",
    "   ○ Normalize numeric values (e.g., MinMaxScaler)  \n",
    "\n",
    "3. Analyze clustering logic & choose method  \n",
    "   ○ Check feature correlation and determine optimal number of clusters  \n",
    "\n",
    "4. Apply clustering algorithm  \n",
    "   ○ Use K-Means to segment users based on behavior  \n",
    "\n",
    "5. Interpret clusters & assign perks  \n",
    "   ○ Match perk logic to the dominant patterns in each group  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce12657",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4b5320;\">◼</span> Step 1 – User-Level Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee8395",
   "metadata": {},
   "source": [
    "To segment customers meaningfully, we first create a single user-level DataFrame that aggregates all relevant behavioral metrics from the cleaned `silver` tables.\n",
    "\n",
    "These features will serve as input for clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862fe0ef",
   "metadata": {},
   "source": [
    "**Features to Aggregate Per User**\n",
    "| Feature                     | Source Table        | Description                                                                 |\n",
    "|-----------------------------|---------------------|-----------------------------------------------------------------------------|\n",
    "| `total_sessions`           | sessions_silver     | Total number of sessions per user                                           |\n",
    "| `cancellation_rate`        | sessions_silver     | Share of sessions marked as cancellations                                   |\n",
    "| `discount_usage_rate`      | sessions_silver     | Share of sessions where any discount was applied                            |\n",
    "| `total_nights`             | hotels_silver       | Total number of nights across all hotel bookings                            |\n",
    "| `total_checked_bags`       | flights_silver      | Total number of checked bags across all flights                             |\n",
    "| `total_base_fare`          | flights_silver      | Sum of base flight fares — indicates price sensitivity or booking class     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6908cb6",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#800020;\">◼</span> Aggregation Code – Create `df_user_features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4ec6db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Create a copy to avoid SettingWithCopyWarning\n",
    "df_sessions_silver = df_sessions_silver.copy()\n",
    "\n",
    "# 🧩 Add helper column: True if any discount was used in a session\n",
    "df_sessions_silver[\"used_any_discount\"] = df_sessions_silver[\"flight_discount\"] | df_sessions_silver[\"hotel_discount\"]\n",
    "\n",
    "# 📊 Aggregate session-level features per user\n",
    "sessions_agg = df_sessions_silver.groupby(\"user_id\").agg(\n",
    "    total_sessions=(\"session_id\", \"count\"),\n",
    "    cancellation_rate=(\"cancellation\", \"mean\"),\n",
    "    discount_usage_rate=(\"used_any_discount\", \"mean\")\n",
    ").reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b76a2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ User-level features aggregated.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_sessions",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cancellation_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "discount_usage_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total_nights",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total_checked_bags",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total_base_fare",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "2e25afbb-3d7e-49dc-9083-e7bc6afbc011",
       "rows": [
        [
         "0",
         "144844",
         "9",
         "0.3333333333333333",
         "0.4444444444444444",
         "35.0",
         "2.0",
         "7827.97"
        ],
        [
         "1",
         "204943",
         "10",
         "0.1",
         "0.2",
         "40.0",
         "8.0",
         "3940.79"
        ],
        [
         "2",
         "260230",
         "10",
         "0.1",
         "0.3",
         "18.0",
         "6.0",
         "2911.17"
        ],
        [
         "3",
         "290123",
         "8",
         "0.0",
         "0.0",
         "22.0",
         "7.0",
         "4939.42"
        ],
        [
         "4",
         "405311",
         "8",
         "0.125",
         "0.625",
         "19.0",
         "2.0",
         "2175.21"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>total_sessions</th>\n",
       "      <th>cancellation_rate</th>\n",
       "      <th>discount_usage_rate</th>\n",
       "      <th>total_nights</th>\n",
       "      <th>total_checked_bags</th>\n",
       "      <th>total_base_fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>144844</td>\n",
       "      <td>9</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7827.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204943</td>\n",
       "      <td>10</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3940.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>260230</td>\n",
       "      <td>10</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2911.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>290123</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4939.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>405311</td>\n",
       "      <td>8</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2175.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  total_sessions  cancellation_rate  discount_usage_rate  \\\n",
       "0   144844               9           0.333333             0.444444   \n",
       "1   204943              10           0.100000             0.200000   \n",
       "2   260230              10           0.100000             0.300000   \n",
       "3   290123               8           0.000000             0.000000   \n",
       "4   405311               8           0.125000             0.625000   \n",
       "\n",
       "   total_nights  total_checked_bags  total_base_fare  \n",
       "0          35.0                 2.0          7827.97  \n",
       "1          40.0                 8.0          3940.79  \n",
       "2          18.0                 6.0          2911.17  \n",
       "3          22.0                 7.0          4939.42  \n",
       "4          19.0                 2.0          2175.21  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Prepare sessions ---\n",
    "# Add helper column: True if user used any discount (flight or hotel)\n",
    "df_sessions_silver.loc[:, \"used_any_discount\"] = (\n",
    "    df_sessions_silver[\"flight_discount\"] | df_sessions_silver[\"hotel_discount\"]\n",
    ")\n",
    "\n",
    "# Aggregate session-based metrics\n",
    "sessions_agg = df_sessions_silver.groupby(\"user_id\").agg(\n",
    "    total_sessions=(\"session_id\", \"count\"),\n",
    "    cancellation_rate=(\"cancellation\", \"mean\"),\n",
    "    discount_usage_rate=(\"used_any_discount\", \"mean\")\n",
    ")\n",
    "\n",
    "# --- Prepare hotels ---\n",
    "hotels_agg = df_hotels_silver.groupby(\"trip_id\")[\"nights\"].sum().reset_index()\n",
    "hotels_sessions = df_sessions_silver[[\"user_id\", \"trip_id\"]].drop_duplicates()\n",
    "hotels_joined = hotels_sessions.merge(hotels_agg, on=\"trip_id\", how=\"left\")\n",
    "hotel_user_agg = hotels_joined.groupby(\"user_id\")[\"nights\"].sum().rename(\"total_nights\")\n",
    "\n",
    "# --- Prepare flights ---\n",
    "flights_agg = df_flights_silver.groupby(\"trip_id\").agg(\n",
    "    total_checked_bags=(\"checked_bags\", \"sum\"),\n",
    "    total_base_fare=(\"base_fare_usd\", \"sum\")\n",
    ").reset_index()\n",
    "flights_sessions = df_sessions_silver[[\"user_id\", \"trip_id\"]].drop_duplicates()\n",
    "flights_joined = flights_sessions.merge(flights_agg, on=\"trip_id\", how=\"left\")\n",
    "flight_user_agg = flights_joined.groupby(\"user_id\").agg(\n",
    "    total_checked_bags=(\"total_checked_bags\", \"sum\"),\n",
    "    total_base_fare=(\"total_base_fare\", \"sum\")\n",
    ")\n",
    "\n",
    "# --- Merge all user-level features ---\n",
    "df_user_features = (\n",
    "    sessions_agg\n",
    "    .join(hotel_user_agg, how=\"left\")\n",
    "    .join(flight_user_agg, how=\"left\")\n",
    "    .fillna(0)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(\"✅ User-level features aggregated.\")\n",
    "df_user_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d3a10b",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#800020;\">◼</span> Histogram: Total Sessions per User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c36601c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_users' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m plt.figure(figsize=(\u001b[32m8\u001b[39m, \u001b[32m5\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mdf_users\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mtotal_sessions\u001b[39m\u001b[33m'\u001b[39m].hist(bins=\u001b[32m30\u001b[39m, edgecolor=\u001b[33m'\u001b[39m\u001b[33mblack\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mDistribution of Total Sessions per User\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m plt.xlabel(\u001b[33m'\u001b[39m\u001b[33mTotal Sessions\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_users' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "df_users['total_sessions'].hist(bins=30, edgecolor='black')\n",
    "plt.title('Distribution of Total Sessions per User')\n",
    "plt.xlabel('Total Sessions')\n",
    "plt.ylabel('User Count')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d28944",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#800020;\">◼</span> Boxplot: Flight Base Fare (USD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5fd81029",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_flights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      4\u001b[39m plt.figure(figsize=(\u001b[32m8\u001b[39m, \u001b[32m4\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m sns.boxplot(x=\u001b[43mdf_flights\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mbase_fare_usd\u001b[39m\u001b[33m'\u001b[39m], color=\u001b[33m'\u001b[39m\u001b[33mskyblue\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mBoxplot of Flight Base Fare (USD)\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m plt.xlabel(\u001b[33m'\u001b[39m\u001b[33mBase Fare (USD)\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_flights' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.boxplot(x=df_flights['base_fare_usd'], color='skyblue')\n",
    "plt.title('Boxplot of Flight Base Fare (USD)')\n",
    "plt.xlabel('Base Fare (USD)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae401df0",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4b5320;\">◼</span> Step 2 – Feature Scaling for Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbedd9c5",
   "metadata": {},
   "source": [
    "To ensure all features contribute equally to the clustering process, we standardize selected user-level metrics using `MinMaxScaler`. This transforms all values into a uniform range between 0 and 1.\n",
    "\n",
    "**Features scaled:**\n",
    "- `total_sessions`\n",
    "- `cancellation_rate`\n",
    "- `discount_usage_rate`\n",
    "- `total_nights`\n",
    "- `total_checked_bags`\n",
    "- `total_base_fare`\n",
    "\n",
    "The scaled values are stored in a new DataFrame (`df_scaled`) and are now ready for use in the clustering algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9a3abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 🧮 Features to scale\n",
    "features_to_scale = [\n",
    "    \"total_sessions\",\n",
    "    \"cancellation_rate\",\n",
    "    \"discount_usage_rate\",\n",
    "    \"total_nights\",\n",
    "    \"total_checked_bags\",\n",
    "    \"total_base_fare\"\n",
    "]\n",
    "\n",
    "# 🔁 Standardize values to [0, 1]\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(df_user_features[features_to_scale])\n",
    "\n",
    "# 💾 Store scaled features in new DataFrame\n",
    "df_scaled = pd.DataFrame(X_scaled, columns=features_to_scale)\n",
    "df_scaled[\"user_id\"] = df_user_features[\"user_id\"].values\n",
    "\n",
    "print(\"✅ Scaled features ready for clustering.\")\n",
    "df_scaled.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0f5124",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#800020;\">◼</span> Export Gold Tables for Manual AWS S3 Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b433c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Gold DataFrames (filtered for cohort and ready for clustering)\n",
    "df_flights_gold = df_flights_silver\n",
    "df_hotels_gold = df_hotels_silver\n",
    "df_sessions_gold = df_sessions_silver\n",
    "df_users_gold = df_users_silver\n",
    "\n",
    "# Folder to save locally before manual S3 upload\n",
    "gold_local_path = \"gold_exports/\"\n",
    "os.makedirs(gold_local_path, exist_ok=True)\n",
    "\n",
    "# Tables to save\n",
    "tables = {\n",
    "    \"flights_gold\": df_flights_gold,\n",
    "    \"users_gold\": df_users_gold,\n",
    "    \"hotels_gold\": df_hotels_gold,\n",
    "    \"sessions_gold\": df_sessions_gold,\n",
    "    \"user_features_gold\": df_user_features  # Newly added gold-layer export\n",
    "}\n",
    "\n",
    "# Save each table as CSV locally\n",
    "for name, df in tables.items():\n",
    "    try:\n",
    "        path = os.path.join(gold_local_path, f\"{name}.csv\")\n",
    "        df.to_csv(path, index=False)\n",
    "        print(f\"✅ Exported: {path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in {name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accf281c",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4b5320;\">◼</span> Step 3 – Clustering the Users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32593bdc",
   "metadata": {},
   "source": [
    "**What we’ll do in this step:**\n",
    "\n",
    "- Decide how many clusters to try (e.g. k=3, k=4, k=5)\n",
    "\n",
    "- Fit the KMeans model on df_scaled (without user_id)\n",
    "\n",
    "- Store the assigned cluster label back in df_user_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425c041c",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#800020;\">◼</span> Feature Correlation Matrix – Identify Redundancies Before Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bac275f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['cluster'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 🔍 Only numeric features for correlation\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m corr_data = \u001b[43mdf_user_features\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcluster\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# 📊 Plot the correlation matrix\u001b[39;00m\n\u001b[32m      8\u001b[39m plt.figure(figsize=(\u001b[32m10\u001b[39m, \u001b[32m6\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Git-GitHub\\Repositories\\Mastery-Project-Masterschool\\mastery-project-masterschool\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5433\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5434\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5435\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5442\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5443\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5444\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5445\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5446\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5579\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5580\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5581\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5582\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5583\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5584\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5585\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5586\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5587\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5588\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5589\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Git-GitHub\\Repositories\\Mastery-Project-Masterschool\\mastery-project-masterschool\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4786\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4787\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4788\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4790\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4791\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Git-GitHub\\Repositories\\Mastery-Project-Masterschool\\mastery-project-masterschool\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4828\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4829\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4830\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4831\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4833\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4834\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Git-GitHub\\Repositories\\Mastery-Project-Masterschool\\mastery-project-masterschool\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7068\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7069\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7070\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7071\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
      "\u001b[31mKeyError\u001b[39m: \"['cluster'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 🔍 Only numeric features for correlation\n",
    "corr_data = df_user_features.drop(columns=[\"user_id\", \"cluster\"])\n",
    "\n",
    "# 📊 Plot the correlation matrix\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(corr_data.corr(), annot=True, cmap=\"YlGnBu\", linewidths=0.5)\n",
    "plt.title(\"Correlation Matrix – User-Level Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0737b816",
   "metadata": {},
   "source": [
    "No strong multicollinearity → we don’t need to drop or merge features due to redundancy.\n",
    "\n",
    "The features are informationally diverse, which is great for clustering – K-Means can now form groups based on genuinely different behaviors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e42edb",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#800020;\">◼</span> Determine Optimal `k` – Elbow Curve for K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53db0f1",
   "metadata": {},
   "source": [
    "We use the elbow method to plot inertia (clustering error) for a range of cluster counts.  \n",
    "The \"elbow point\" indicates a good balance between cluster compactness and generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da59cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Drop user_id column before clustering\n",
    "X = df_scaled.drop(columns=[\"user_id\"])\n",
    "\n",
    "# Try different k values\n",
    "inertia = []\n",
    "k_range = range(1, 11)\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=\"auto\")\n",
    "    kmeans.fit(X)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot elbow curve\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(k_range, inertia, marker=\"o\")\n",
    "plt.title(\"Elbow Curve – K-Means Inertia vs. Cluster Count\")\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c73dbed",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4b5320;\">◼</span> Step 4 – Apply KMeans Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517af197",
   "metadata": {},
   "source": [
    "We apply KMeans clustering with `k = 4` and assign each user a cluster label for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a83695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 🎯 Drop user_id for clustering\n",
    "X = df_scaled.drop(columns=[\"user_id\"])\n",
    "\n",
    "# 🔢 Set number of clusters from elbow method\n",
    "k = 4  # ⬅️ ggf. anpassen\n",
    "\n",
    "# 🚀 Apply K-Means clustering\n",
    "kmeans = KMeans(n_clusters=k, random_state=42, n_init=\"auto\")\n",
    "df_scaled[\"cluster\"] = kmeans.fit_predict(X)\n",
    "\n",
    "# 🔄 Add cluster labels to original user features\n",
    "df_user_features[\"cluster\"] = df_scaled[\"cluster\"]\n",
    "\n",
    "# 🎨 PCA for 2D visualization\n",
    "pca = PCA(n_components=2)\n",
    "components = pca.fit_transform(X)\n",
    "\n",
    "# 📊 Plot PCA projection with clusters\n",
    "plt.figure(figsize=(8, 5))\n",
    "scatter = plt.scatter(\n",
    "    components[:, 0], components[:, 1],\n",
    "    c=df_scaled[\"cluster\"],\n",
    "    cmap=\"Set2\",\n",
    "    s=40,\n",
    "    edgecolor='k'\n",
    ")\n",
    "plt.title(f\"User Segmentation – PCA Projection (k={k})\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.grid(True)\n",
    "plt.legend(*scatter.legend_elements(), title=\"Cluster\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdff5324",
   "metadata": {},
   "source": [
    "**What I think is happening:**<br>\n",
    "<br>\n",
    "- The users on the left (green) are one type – maybe low spenders or low activity.\n",
    "\n",
    "- The users on the right (blue) seem very different – maybe they book a lot or spend more.\n",
    "\n",
    "- The yellow ones are more spread out, so maybe they’re a mixed group.\n",
    "\n",
    "- The gray ones are very tight and close – maybe their behavior is really similar.\n",
    "\n",
    "- I can't say exactly what each group means just by looking at the chart, so I plan to check the average behavior per cluster next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b2d31d",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4b5320;\">◼</span> Step 5 – Interpret Clusters & Assign Perks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc3bd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cluster-wise means from the scaled data\n",
    "scaled_means = df_scaled.drop(columns=\"user_id\").groupby(\"cluster\").mean()\n",
    "\n",
    "# Transpose the DataFrame for better plotting (features on x-axis)\n",
    "scaled_means.T.plot(kind=\"bar\", figsize=(10, 6), colormap=\"Set2\")\n",
    "\n",
    "plt.title(\"Average Scaled Feature Values per Cluster\")\n",
    "plt.ylabel(\"Scaled Value (0–1)\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c705447",
   "metadata": {},
   "source": [
    "**Cluster Interpretation (based on the bar chart)**\n",
    "\n",
    "| Cluster    | What I see |\n",
    "|------------|------------|\n",
    "| **Cluster 0** | These users have **high checked bags** and **high base fares**, but **few sessions**. Maybe they travel rarely, but when they do, they **spend more** and **bring more luggage**. |\n",
    "| **Cluster 1** | They use **a lot of discounts**, have **medium cancellation rates**, and **spend less overall**. Sounds like **budget-conscious travelers** who book carefully. |\n",
    "| **Cluster 2** | This group is **high on almost everything** – sessions, nights, bags, fare. They look like **power users**, but also **cancel the most**. Maybe they book a lot but often change plans. |\n",
    "| **Cluster 3** | This group is **low to medium on all features**. Not much stands out. They seem like **average or low-engagement users**. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41677000",
   "metadata": {},
   "source": [
    "We now examine each cluster’s average behavior to determine which **perk** fits best. This is based on aggregated metrics like discount usage, cancellations, and travel activity. We calculate mean feature values for each cluster to detect dominant patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03df0556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average behavior per cluster\n",
    "cluster_summary = df_user_features.groupby(\"cluster\").mean(numeric_only=True)\n",
    "cluster_summary.style.background_gradient(cmap=\"YlGnBu\").format(\"{:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d57d99",
   "metadata": {},
   "source": [
    "**Cluster Interpretation & Perk Assignment**\n",
    "| Cluster | Behavioral Summary                                                                 | Assigned Perk                  |\n",
    "|---------|-------------------------------------------------------------------------------------|--------------------------------|\n",
    "| 0       | High discount usage, low cancellations, active in both flights and hotels          | 🎁 Exclusive Discounts         |\n",
    "| 1       | Low spenders, few sessions, little engagement                                      | 🧳 Free Checked Bag            |\n",
    "| 2       | High cancellation rate, medium session volume                                      | ❌ No Cancellation Fees        |\n",
    "| 3       | Frequent hotel+flight usage, long nights, high fares                               | 🏨 1 Night Free with Flight    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58c6716",
   "metadata": {},
   "source": [
    "# <span style=\"color:#e67e22;\">◼</span> **Machine Learning - Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b440ac6",
   "metadata": {},
   "source": [
    "We train a classifier to predict user clusters from behavioral features.  \n",
    "This allows perk recommendations to be extended to new users in a scalable, supervised way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec997438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Step 1 – Features (X) and target (y)\n",
    "X = df_user_features[[\n",
    "    \"total_sessions\",\n",
    "    \"cancellation_rate\",\n",
    "    \"discount_usage_rate\",\n",
    "    \"total_nights\",\n",
    "    \"total_checked_bags\",\n",
    "    \"total_base_fare\"\n",
    "]]\n",
    "\n",
    "y = df_user_features[\"cluster\"]\n",
    "\n",
    "# Step 2 – Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Step 3 – Train model\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 4 – Evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"✅ Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"🧩 Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d5e6dc",
   "metadata": {},
   "source": [
    "🎯 Random Forest Classification to Validate Clusters\n",
    "\n",
    "I trained a **Random Forest model** to predict which cluster each user belongs to, using the following features:\n",
    "\n",
    "- `total_sessions`\n",
    "- `cancellation_rate`\n",
    "- `discount_usage_rate`\n",
    "- `total_nights`\n",
    "- `total_checked_bags`\n",
    "- `total_base_fare`\n",
    "\n",
    "I used a **train-test split (80/20)** and evaluated the model on the test set.\n",
    "\n",
    "---\n",
    "\n",
    "✅ Classification Report Summary\n",
    "\n",
    "- **Accuracy**: 94%\n",
    "- **Precision / Recall / F1** scores are all strong, especially for clusters 1, 2, and 3.\n",
    "- Cluster 0 had one misclassified user (predicted as Cluster 1).\n",
    "- All other clusters were predicted correctly.\n",
    "\n",
    "---\n",
    "\n",
    "🧩 Confusion Matrix\n",
    "\n",
    "| Actual \\ Predicted | Cluster 0 | Cluster 1 | Cluster 2 | Cluster 3 |\n",
    "|--------------------|-----------|-----------|-----------|-----------|\n",
    "| **Cluster 0**      | 2         | 1         | 0         | 0         |\n",
    "| **Cluster 1**      | 0         | 5         | 0         | 0         |\n",
    "| **Cluster 2**      | 0         | 0         | 1         | 0         |\n",
    "| **Cluster 3**      | 0         | 0         | 0         | 7         |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a604219a",
   "metadata": {},
   "source": [
    "**Cluster Validation – Linking Classification to Perk Assignment**\n",
    "\n",
    "| Cluster | Classification Accuracy | Behavioral Summary (from KMeans)                          | Assigned Perk                |\n",
    "|---------|--------------------------|------------------------------------------------------------|------------------------------|\n",
    "| 0       | 2/3 correct (1 misclass.) | Few sessions, high fares and luggage                       | 🎁 Exclusive Discounts       |\n",
    "| 1       | 5/5 correct               | Budget-conscious, medium cancellations, discounts          | 🧳 Free Checked Bag          |\n",
    "| 2       | 1/1 correct               | High on all metrics, cancels a lot (power users)           | ❌ No Cancellation Fees      |\n",
    "| 3       | 7/7 correct               | Average to low usage                                       | 🏨 1 Night Free with Flight  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe8da08",
   "metadata": {},
   "source": [
    "**Cluster Validation & Perk Confirmation**\n",
    "\n",
    "To validate whether the clusters derived from the K-Means algorithm truly reflect distinct user behavior, I trained a Random Forest classifier. The goal was to predict each user's cluster assignment based solely on the six aggregated behavioral features that were also used for clustering.\n",
    "\n",
    "Using an 80/20 train-test split, the model achieved an accuracy of 94%. All clusters were predicted correctly except for one user from Cluster 0, who was misclassified as Cluster 1.\n",
    "\n",
    "This strong performance indicates that the clustering is not random but based on consistent patterns in user behavior. Since each cluster was mapped to a specific perk, the classification results also support the logic behind the perk assignments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mastery-project)",
   "language": "python",
   "name": "mastery-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
